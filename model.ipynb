{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28fbefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d492fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_file = 'train-images-idx3-ubyte'\n",
    "train_labels_file = 'train-labels-idx1-ubyte'\n",
    "test_images_file  = 't10k-images-idx3-ubyte'\n",
    "test_labels_file  = 't10k-labels-idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59f3481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = int.from_bytes(f.read(4), 'big')  # Magic number\n",
    "        num_images = int.from_bytes(f.read(4), 'big')\n",
    "        rows = int.from_bytes(f.read(4), 'big')\n",
    "        cols = int.from_bytes(f.read(4), 'big')\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return images.reshape(num_images, rows, cols)\n",
    "\n",
    "def load_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = int.from_bytes(f.read(4), 'big')  # Magic number\n",
    "        num_labels = int.from_bytes(f.read(4), 'big')\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ceeee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_images(train_images_file)\n",
    "train_labels = load_labels(train_labels_file)\n",
    "test_images = load_images(test_images_file)\n",
    "test_labels = load_labels(test_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4d87491",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c2a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images.reshape(-1, 28*28)\n",
    "X_test = test_images.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9768487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.2573 - accuracy: 0.9249 - val_loss: 0.1172 - val_accuracy: 0.9665\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.1086 - accuracy: 0.9663 - val_loss: 0.0856 - val_accuracy: 0.9762\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0766 - accuracy: 0.9763 - val_loss: 0.0870 - val_accuracy: 0.9745\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.0572 - accuracy: 0.9816 - val_loss: 0.0793 - val_accuracy: 0.9760\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.0442 - accuracy: 0.9855 - val_loss: 0.0854 - val_accuracy: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e481d598d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax') \n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, train_labels, epochs=5, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df738435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def predict_from_png(file_path):\n",
    "    # Load and preprocess the PNG image\n",
    "    img = Image.open(file_path)\n",
    "    \n",
    "    # Convert to grayscale if not already\n",
    "    img = img.convert('L')\n",
    "    \n",
    "    # Resize to 28x28 pixels\n",
    "    img = img.resize((28, 28))\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Normalize pixel values to 0-1 range\n",
    "    img_array = img_array.astype('float32') / 255.0\n",
    "    \n",
    "    # Reshape to match model input shape (flatten to 784 features)\n",
    "    img_array = img_array.reshape(1, 28*28)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction[0])\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Example usage:\n",
    "# predicted_class, confidence = predict_from_png('path/to/your/image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21a7c94",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'E:\\\\Cursor\\\\Machine-Learning-Specialization-Coursera-main\\\\HandwrittenDigitRecognizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the path to your PNG image: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m predicted_class, confidence \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_from_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m, in \u001b[0;36mpredict_from_png\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_from_png\u001b[39m(file_path):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Load and preprocess the PNG image\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Convert to grayscale if not already\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ARNAV KAMAL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'E:\\\\Cursor\\\\Machine-Learning-Specialization-Coursera-main\\\\HandwrittenDigitRecognizer'"
     ]
    }
   ],
   "source": [
    "file_path = input(\"Enter the path to your PNG image: \")\n",
    "predicted_class, confidence = predict_from_png(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
